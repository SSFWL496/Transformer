2021-11-24 01:12:41 | INFO | fairseq.distributed_utils | distributed init (rank 3): tcp://localhost:15613
2021-11-24 01:12:41 | INFO | fairseq.distributed_utils | distributed init (rank 2): tcp://localhost:15613
2021-11-24 01:12:41 | INFO | fairseq.distributed_utils | distributed init (rank 0): tcp://localhost:15613
2021-11-24 01:12:41 | INFO | fairseq.distributed_utils | distributed init (rank 1): tcp://localhost:15613
2021-11-24 01:12:41 | INFO | fairseq.distributed_utils | initialized host ip-219-216-64-168.neu.edu.cn as rank 1
2021-11-24 01:12:42 | INFO | fairseq.distributed_utils | initialized host ip-219-216-64-168.neu.edu.cn as rank 3
2021-11-24 01:12:42 | INFO | fairseq.distributed_utils | initialized host ip-219-216-64-168.neu.edu.cn as rank 2
2021-11-24 01:12:42 | INFO | fairseq.distributed_utils | initialized host ip-219-216-64-168.neu.edu.cn as rank 0
2021-11-24 01:12:44 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_iwslt_de_en_tiny_6_1', attention_dropout=0.1, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin/iwslt14de2en', data_buffer_size=10, dataset_impl=None, ddp_backend='no_c10d', decay_num=100000, decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=1, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, difficult_queue_size=20000, disable_validation=False, distil_curiosity_rate=0.75, distil_rate=0.5, distil_rate_decrease_start_step=-1, distil_schedule='unchange', distil_strategy='normal', distil_weight_strategy='', distributed_backend='nccl', distributed_init_method='tcp://localhost:15613', distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=4, distributed_wrapper='DDP', dropout=0.3, embedding_alpha=1.0, embedding_norm='', empty_cache_freq=0, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, k_only=False, kd_rescale=1.0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=60, kl_loss_combine_rate=0.5, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='tqdm', log_interval=100, lr=[0.0007], lr_scheduler='inverse_sqrt', max_epoch=150, max_relative_length=-1, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=1e-09, mix_schedule='teacher', model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=4, num_batch_buckets=0, num_workers=1, open_noise_teacher=False, optimizer='adam', optimizer_overrides='{}', patience=-1, predict_change_margin=0.23, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en', save_interval=1, save_interval_updates=0, seed=2128977, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=False, sigmoid_alpha=10, sigmoid_mid=0.5, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, soft_range=1.0, source_lang='de', stop_time_hours=0, target_lang='en', task='translation', teacher_ckpt_path='', teacher_decoder_layers=6, teacher_distil_rate=0.5, teacher_encoder_layers=6, teacher_predict_temperature=1.0, teacher_predict_temperature_schedule='none', teacher_strategy='', tensorboard_logdir='', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[2], upsample_primary=1, use_bmuf=False, use_distillation=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=1e-07, warmup_updates=6000, weight_decay=0.0001, zero_first_token=False)
2021-11-24 01:12:44 | INFO | fairseq.tasks.translation | [de] dictionary: 10152 types
2021-11-24 01:12:44 | INFO | fairseq.tasks.translation | [en] dictionary: 10152 types
2021-11-24 01:12:44 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14de2en/valid.de-en.de
2021-11-24 01:12:44 | INFO | fairseq.data.data_utils | loaded 7283 examples from: data-bin/iwslt14de2en/valid.de-en.en
2021-11-24 01:12:44 | INFO | fairseq.tasks.translation | data-bin/iwslt14de2en valid de-en 7283 examples
2021-11-24 01:12:45 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10152, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(10152, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=1024, bias=True)
        (fc2): Linear(in_features=1024, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=10152, bias=False)
  )
)
2021-11-24 01:12:45 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2021-11-24 01:12:45 | INFO | fairseq_cli.train | model: transformer_iwslt_de_en_tiny_6_1 (TransformerModel)
2021-11-24 01:12:45 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2021-11-24 01:12:45 | INFO | fairseq_cli.train | num. model params: 20968960 (num. trained: 20968960)
2021-11-24 01:12:45 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2021-11-24 01:12:45 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2021-11-24 01:12:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-11-24 01:12:45 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN X (Pascal)                        
2021-11-24 01:12:45 | INFO | fairseq.utils | rank   1: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN X (Pascal)                        
2021-11-24 01:12:45 | INFO | fairseq.utils | rank   2: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN X (Pascal)                        
2021-11-24 01:12:45 | INFO | fairseq.utils | rank   3: capabilities =  6.1  ; total memory = 11.910 GB ; name = TITAN X (Pascal)                        
2021-11-24 01:12:45 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2021-11-24 01:12:45 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2021-11-24 01:12:45 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2021-11-24 01:12:45 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2021-11-24 01:12:45 | INFO | fairseq.trainer | loaded checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint_last.pt (epoch 101 @ 13793 updates)
2021-11-24 01:12:45 | INFO | fairseq.trainer | loading train data for epoch 101
2021-11-24 01:12:45 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14de2en/train.de-en.de
2021-11-24 01:12:45 | INFO | fairseq.data.data_utils | loaded 160239 examples from: data-bin/iwslt14de2en/train.de-en.en
2021-11-24 01:12:45 | INFO | fairseq.tasks.translation | data-bin/iwslt14de2en train de-en 160239 examples
2021-11-24 01:12:45 | INFO | fairseq.trainer | begin training epoch 101
2021-11-24 01:12:49 | INFO | train_inner | epoch 101:      7 / 138 loss=3.945, nll_loss=2.441, distil_rate=0, ppl=5.43, wps=101785, ups=3.57, wpb=28503.3, bsz=1160.2, num_updates=13800, lr=0.000461566, gnorm=0.446, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:13:11 | INFO | train_inner | epoch 101:    107 / 138 loss=3.936, nll_loss=2.43, distil_rate=0, ppl=5.39, wps=127668, ups=4.45, wpb=28660, bsz=1165.5, num_updates=13900, lr=0.000459903, gnorm=0.437, loss_scale=32, train_wall=22, wall=0
2021-11-24 01:13:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:13:21 | INFO | valid | epoch 101 | valid on 'valid' subset | loss 4.401 | nll_loss 2.674 | distil_rate 0 | ppl 6.38 | wps 322844 | wpb 11163.9 | bsz 455.2 | num_updates 13931 | best_loss 4.387
2021-11-24 01:13:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:13:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint101.pt (epoch 101 @ 13931 updates, score 4.401) (writing took 1.2026027140018414 seconds)
2021-11-24 01:13:22 | INFO | fairseq_cli.train | end of epoch 101 (average epoch stats below)
2021-11-24 01:13:22 | INFO | train | epoch 101 | loss 3.941 | nll_loss 2.436 | distil_rate 0 | ppl 5.41 | wps 107726 | ups 3.77 | wpb 28551.3 | bsz 1159.4 | num_updates 13931 | lr 0.000459391 | gnorm 0.444 | loss_scale 32 | train_wall 63 | wall 0
2021-11-24 01:13:22 | INFO | fairseq.trainer | begin training epoch 102
2021-11-24 01:13:39 | INFO | train_inner | epoch 102:     69 / 138 loss=3.941, nll_loss=2.436, distil_rate=0, ppl=5.41, wps=102130, ups=3.58, wpb=28545.1, bsz=1123.2, num_updates=14000, lr=0.000458258, gnorm=0.448, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:13:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:13:57 | INFO | valid | epoch 102 | valid on 'valid' subset | loss 4.387 | nll_loss 2.661 | distil_rate 0 | ppl 6.33 | wps 327005 | wpb 11163.9 | bsz 455.2 | num_updates 14069 | best_loss 4.387
2021-11-24 01:13:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:14:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint102.pt (epoch 102 @ 14069 updates, score 4.387) (writing took 3.078105388005497 seconds)
2021-11-24 01:14:00 | INFO | fairseq_cli.train | end of epoch 102 (average epoch stats below)
2021-11-24 01:14:00 | INFO | train | epoch 102 | loss 3.936 | nll_loss 2.431 | distil_rate 0 | ppl 5.39 | wps 103356 | ups 3.62 | wpb 28538.1 | bsz 1157.7 | num_updates 14069 | lr 0.000457132 | gnorm 0.452 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:14:00 | INFO | fairseq.trainer | begin training epoch 103
2021-11-24 01:14:09 | INFO | train_inner | epoch 103:     31 / 138 loss=3.933, nll_loss=2.427, distil_rate=0, ppl=5.38, wps=95872, ups=3.38, wpb=28326.2, bsz=1164.2, num_updates=14100, lr=0.00045663, gnorm=0.461, loss_scale=32, train_wall=22, wall=0
2021-11-24 01:14:32 | INFO | train_inner | epoch 103:    131 / 138 loss=3.934, nll_loss=2.429, distil_rate=0, ppl=5.39, wps=126057, ups=4.37, wpb=28869.4, bsz=1180.2, num_updates=14200, lr=0.000455019, gnorm=0.432, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:14:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:14:36 | INFO | valid | epoch 103 | valid on 'valid' subset | loss 4.401 | nll_loss 2.674 | distil_rate 0 | ppl 6.38 | wps 326243 | wpb 11163.9 | bsz 455.2 | num_updates 14207 | best_loss 4.387
2021-11-24 01:14:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:14:37 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint103.pt (epoch 103 @ 14207 updates, score 4.401) (writing took 1.3674431269973866 seconds)
2021-11-24 01:14:37 | INFO | fairseq_cli.train | end of epoch 103 (average epoch stats below)
2021-11-24 01:14:37 | INFO | train | epoch 103 | loss 3.93 | nll_loss 2.424 | distil_rate 0 | ppl 5.37 | wps 106492 | ups 3.73 | wpb 28553.1 | bsz 1159.8 | num_updates 14207 | lr 0.000454907 | gnorm 0.443 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:14:37 | INFO | fairseq.trainer | begin training epoch 104
2021-11-24 01:15:00 | INFO | train_inner | epoch 104:     93 / 138 loss=3.916, nll_loss=2.408, distil_rate=0, ppl=5.31, wps=99680.3, ups=3.5, wpb=28473.9, bsz=1162.9, num_updates=14300, lr=0.000453425, gnorm=0.442, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:15:10 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:15:13 | INFO | valid | epoch 104 | valid on 'valid' subset | loss 4.411 | nll_loss 2.679 | distil_rate 0 | ppl 6.41 | wps 242660 | wpb 11163.9 | bsz 455.2 | num_updates 14345 | best_loss 4.387
2021-11-24 01:15:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:15:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint104.pt (epoch 104 @ 14345 updates, score 4.411) (writing took 1.610335028002737 seconds)
2021-11-24 01:15:14 | INFO | fairseq_cli.train | end of epoch 104 (average epoch stats below)
2021-11-24 01:15:14 | INFO | train | epoch 104 | loss 3.926 | nll_loss 2.419 | distil_rate 0 | ppl 5.35 | wps 105151 | ups 3.69 | wpb 28534.1 | bsz 1157.6 | num_updates 14345 | lr 0.000452713 | gnorm 0.439 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:15:14 | INFO | fairseq.trainer | begin training epoch 105
2021-11-24 01:15:28 | INFO | train_inner | epoch 105:     55 / 138 loss=3.925, nll_loss=2.419, distil_rate=0, ppl=5.35, wps=100226, ups=3.53, wpb=28429.1, bsz=1156.7, num_updates=14400, lr=0.000451848, gnorm=0.445, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:15:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:15:50 | INFO | valid | epoch 105 | valid on 'valid' subset | loss 4.387 | nll_loss 2.661 | distil_rate 0 | ppl 6.33 | wps 318367 | wpb 11163.9 | bsz 455.2 | num_updates 14483 | best_loss 4.387
2021-11-24 01:15:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:15:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint105.pt (epoch 105 @ 14483 updates, score 4.387) (writing took 2.845592661004048 seconds)
2021-11-24 01:15:53 | INFO | fairseq_cli.train | end of epoch 105 (average epoch stats below)
2021-11-24 01:15:53 | INFO | train | epoch 105 | loss 3.924 | nll_loss 2.417 | distil_rate 0 | ppl 5.34 | wps 102262 | ups 3.58 | wpb 28535.1 | bsz 1157.7 | num_updates 14483 | lr 0.000450551 | gnorm 0.448 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:15:53 | INFO | fairseq.trainer | begin training epoch 106
2021-11-24 01:15:59 | INFO | train_inner | epoch 106:     17 / 138 loss=3.934, nll_loss=2.428, distil_rate=0, ppl=5.38, wps=94744.3, ups=3.32, wpb=28547.6, bsz=1129.5, num_updates=14500, lr=0.000450287, gnorm=0.451, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:16:22 | INFO | train_inner | epoch 106:    117 / 138 loss=3.914, nll_loss=2.405, distil_rate=0, ppl=5.3, wps=124968, ups=4.36, wpb=28681.4, bsz=1179.8, num_updates=14600, lr=0.000448743, gnorm=0.435, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:16:29 | INFO | valid | epoch 106 | valid on 'valid' subset | loss 4.399 | nll_loss 2.668 | distil_rate 0 | ppl 6.35 | wps 305962 | wpb 11163.9 | bsz 455.2 | num_updates 14621 | best_loss 4.387
2021-11-24 01:16:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:16:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint106.pt (epoch 106 @ 14621 updates, score 4.399) (writing took 1.274950245002401 seconds)
2021-11-24 01:16:30 | INFO | fairseq_cli.train | end of epoch 106 (average epoch stats below)
2021-11-24 01:16:30 | INFO | train | epoch 106 | loss 3.918 | nll_loss 2.41 | distil_rate 0 | ppl 5.31 | wps 105750 | ups 3.7 | wpb 28546.6 | bsz 1160.2 | num_updates 14621 | lr 0.00044842 | gnorm 0.442 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:16:30 | INFO | fairseq.trainer | begin training epoch 107
2021-11-24 01:16:50 | INFO | train_inner | epoch 107:     79 / 138 loss=3.913, nll_loss=2.404, distil_rate=0, ppl=5.29, wps=99715.1, ups=3.5, wpb=28499.5, bsz=1152.1, num_updates=14700, lr=0.000447214, gnorm=0.444, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:17:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:17:06 | INFO | valid | epoch 107 | valid on 'valid' subset | loss 4.4 | nll_loss 2.669 | distil_rate 0 | ppl 6.36 | wps 311489 | wpb 11163.9 | bsz 455.2 | num_updates 14759 | best_loss 4.387
2021-11-24 01:17:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:17:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint107.pt (epoch 107 @ 14759 updates, score 4.4) (writing took 1.2296702539970283 seconds)
2021-11-24 01:17:07 | INFO | fairseq_cli.train | end of epoch 107 (average epoch stats below)
2021-11-24 01:17:07 | INFO | train | epoch 107 | loss 3.915 | nll_loss 2.407 | distil_rate 0 | ppl 5.3 | wps 106232 | ups 3.72 | wpb 28533.7 | bsz 1159.5 | num_updates 14759 | lr 0.000446319 | gnorm 0.445 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:17:07 | INFO | fairseq.trainer | begin training epoch 108
2021-11-24 01:17:18 | INFO | train_inner | epoch 108:     41 / 138 loss=3.918, nll_loss=2.41, distil_rate=0, ppl=5.32, wps=101491, ups=3.56, wpb=28490.3, bsz=1147.9, num_updates=14800, lr=0.0004457, gnorm=0.447, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:17:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:17:43 | INFO | valid | epoch 108 | valid on 'valid' subset | loss 4.431 | nll_loss 2.693 | distil_rate 0 | ppl 6.47 | wps 286692 | wpb 11163.9 | bsz 455.2 | num_updates 14897 | best_loss 4.387
2021-11-24 01:17:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:17:44 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint108.pt (epoch 108 @ 14897 updates, score 4.431) (writing took 1.1806666620032047 seconds)
2021-11-24 01:17:44 | INFO | fairseq_cli.train | end of epoch 108 (average epoch stats below)
2021-11-24 01:17:44 | INFO | train | epoch 108 | loss 3.911 | nll_loss 2.402 | distil_rate 0 | ppl 5.29 | wps 107019 | ups 3.75 | wpb 28536 | bsz 1158.4 | num_updates 14897 | lr 0.000444247 | gnorm 0.447 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:17:44 | INFO | fairseq.trainer | begin training epoch 109
2021-11-24 01:17:46 | INFO | train_inner | epoch 109:      3 / 138 loss=3.911, nll_loss=2.403, distil_rate=0, ppl=5.29, wps=100606, ups=3.54, wpb=28451.8, bsz=1170.5, num_updates=14900, lr=0.000444202, gnorm=0.454, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:18:09 | INFO | train_inner | epoch 109:    103 / 138 loss=3.91, nll_loss=2.401, distil_rate=0, ppl=5.28, wps=124749, ups=4.36, wpb=28594, bsz=1149, num_updates=15000, lr=0.000442719, gnorm=0.434, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:18:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:18:20 | INFO | valid | epoch 109 | valid on 'valid' subset | loss 4.422 | nll_loss 2.689 | distil_rate 0 | ppl 6.45 | wps 320808 | wpb 11163.9 | bsz 455.2 | num_updates 15035 | best_loss 4.387
2021-11-24 01:18:20 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:18:22 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint109.pt (epoch 109 @ 15035 updates, score 4.422) (writing took 1.5526474040016183 seconds)
2021-11-24 01:18:22 | INFO | fairseq_cli.train | end of epoch 109 (average epoch stats below)
2021-11-24 01:18:22 | INFO | train | epoch 109 | loss 3.907 | nll_loss 2.398 | distil_rate 0 | ppl 5.27 | wps 104996 | ups 3.68 | wpb 28539.6 | bsz 1158 | num_updates 15035 | lr 0.000442203 | gnorm 0.44 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:18:22 | INFO | fairseq.trainer | begin training epoch 110
2021-11-24 01:18:38 | INFO | train_inner | epoch 110:     65 / 138 loss=3.886, nll_loss=2.374, distil_rate=0, ppl=5.19, wps=98710.2, ups=3.46, wpb=28521.9, bsz=1193.7, num_updates=15100, lr=0.00044125, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:18:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:18:57 | INFO | valid | epoch 110 | valid on 'valid' subset | loss 4.406 | nll_loss 2.671 | distil_rate 0 | ppl 6.37 | wps 244833 | wpb 11163.9 | bsz 455.2 | num_updates 15173 | best_loss 4.387
2021-11-24 01:18:57 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:18:59 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint110.pt (epoch 110 @ 15173 updates, score 4.406) (writing took 1.2936009160039248 seconds)
2021-11-24 01:18:59 | INFO | fairseq_cli.train | end of epoch 110 (average epoch stats below)
2021-11-24 01:18:59 | INFO | train | epoch 110 | loss 3.905 | nll_loss 2.396 | distil_rate 0 | ppl 5.26 | wps 105746 | ups 3.71 | wpb 28536 | bsz 1156.1 | num_updates 15173 | lr 0.000440188 | gnorm 0.443 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:18:59 | INFO | fairseq.trainer | begin training epoch 111
2021-11-24 01:19:06 | INFO | train_inner | epoch 111:     27 / 138 loss=3.918, nll_loss=2.41, distil_rate=0, ppl=5.32, wps=100884, ups=3.55, wpb=28419.7, bsz=1133.2, num_updates=15200, lr=0.000439797, gnorm=0.448, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:19:29 | INFO | train_inner | epoch 111:    127 / 138 loss=3.9, nll_loss=2.39, distil_rate=0, ppl=5.24, wps=125206, ups=4.35, wpb=28784.6, bsz=1162.2, num_updates=15300, lr=0.000438357, gnorm=0.442, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:19:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:19:34 | INFO | valid | epoch 111 | valid on 'valid' subset | loss 4.397 | nll_loss 2.662 | distil_rate 0 | ppl 6.33 | wps 327013 | wpb 11163.9 | bsz 455.2 | num_updates 15311 | best_loss 4.387
2021-11-24 01:19:34 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:19:36 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint111.pt (epoch 111 @ 15311 updates, score 4.397) (writing took 1.22636677200353 seconds)
2021-11-24 01:19:36 | INFO | fairseq_cli.train | end of epoch 111 (average epoch stats below)
2021-11-24 01:19:36 | INFO | train | epoch 111 | loss 3.901 | nll_loss 2.391 | distil_rate 0 | ppl 5.24 | wps 106902 | ups 3.75 | wpb 28534.4 | bsz 1158.4 | num_updates 15311 | lr 0.0004382 | gnorm 0.45 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:19:36 | INFO | fairseq.trainer | begin training epoch 112
2021-11-24 01:19:58 | INFO | train_inner | epoch 112:     89 / 138 loss=3.908, nll_loss=2.399, distil_rate=0, ppl=5.27, wps=100955, ups=3.55, wpb=28441, bsz=1132.5, num_updates=15400, lr=0.000436931, gnorm=0.449, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:20:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:20:11 | INFO | valid | epoch 112 | valid on 'valid' subset | loss 4.401 | nll_loss 2.668 | distil_rate 0 | ppl 6.36 | wps 320960 | wpb 11163.9 | bsz 455.2 | num_updates 15449 | best_loss 4.387
2021-11-24 01:20:11 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:20:13 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint112.pt (epoch 112 @ 15449 updates, score 4.401) (writing took 1.4416095500055235 seconds)
2021-11-24 01:20:13 | INFO | fairseq_cli.train | end of epoch 112 (average epoch stats below)
2021-11-24 01:20:13 | INFO | train | epoch 112 | loss 3.895 | nll_loss 2.385 | distil_rate 0 | ppl 5.22 | wps 106327 | ups 3.73 | wpb 28538.2 | bsz 1158.6 | num_updates 15449 | lr 0.000436238 | gnorm 0.447 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:20:13 | INFO | fairseq.trainer | begin training epoch 113
2021-11-24 01:20:26 | INFO | train_inner | epoch 113:     51 / 138 loss=3.881, nll_loss=2.368, distil_rate=0, ppl=5.16, wps=100460, ups=3.52, wpb=28532.1, bsz=1189, num_updates=15500, lr=0.00043552, gnorm=0.452, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:20:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:20:48 | INFO | valid | epoch 113 | valid on 'valid' subset | loss 4.411 | nll_loss 2.675 | distil_rate 0 | ppl 6.39 | wps 221326 | wpb 11163.9 | bsz 455.2 | num_updates 15587 | best_loss 4.387
2021-11-24 01:20:48 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:20:50 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint113.pt (epoch 113 @ 15587 updates, score 4.411) (writing took 1.633421313999861 seconds)
2021-11-24 01:20:50 | INFO | fairseq_cli.train | end of epoch 113 (average epoch stats below)
2021-11-24 01:20:50 | INFO | train | epoch 113 | loss 3.894 | nll_loss 2.383 | distil_rate 0 | ppl 5.21 | wps 105755 | ups 3.71 | wpb 28536.7 | bsz 1158.9 | num_updates 15587 | lr 0.000434303 | gnorm 0.448 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:20:50 | INFO | fairseq.trainer | begin training epoch 114
2021-11-24 01:20:55 | INFO | train_inner | epoch 114:     13 / 138 loss=3.894, nll_loss=2.383, distil_rate=0, ppl=5.22, wps=99877.2, ups=3.51, wpb=28460.9, bsz=1151.8, num_updates=15600, lr=0.000434122, gnorm=0.453, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:21:18 | INFO | train_inner | epoch 114:    113 / 138 loss=3.891, nll_loss=2.38, distil_rate=0, ppl=5.2, wps=124411, ups=4.34, wpb=28647.6, bsz=1161.6, num_updates=15700, lr=0.000432737, gnorm=0.434, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:21:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:21:26 | INFO | valid | epoch 114 | valid on 'valid' subset | loss 4.403 | nll_loss 2.671 | distil_rate 0 | ppl 6.37 | wps 318561 | wpb 11163.9 | bsz 455.2 | num_updates 15725 | best_loss 4.387
2021-11-24 01:21:26 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:21:28 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint114.pt (epoch 114 @ 15725 updates, score 4.403) (writing took 1.768867691003834 seconds)
2021-11-24 01:21:28 | INFO | fairseq_cli.train | end of epoch 114 (average epoch stats below)
2021-11-24 01:21:28 | INFO | train | epoch 114 | loss 3.888 | nll_loss 2.376 | distil_rate 0 | ppl 5.19 | wps 104607 | ups 3.66 | wpb 28553.7 | bsz 1159.2 | num_updates 15725 | lr 0.000432393 | gnorm 0.441 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:21:28 | INFO | fairseq.trainer | begin training epoch 115
2021-11-24 01:21:46 | INFO | train_inner | epoch 115:     75 / 138 loss=3.873, nll_loss=2.359, distil_rate=0, ppl=5.13, wps=99294.2, ups=3.48, wpb=28517.9, bsz=1165.6, num_updates=15800, lr=0.000431365, gnorm=0.447, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:21:57 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-11-24 01:22:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:22:03 | INFO | valid | epoch 115 | valid on 'valid' subset | loss 4.39 | nll_loss 2.659 | distil_rate 0 | ppl 6.32 | wps 219432 | wpb 11163.9 | bsz 455.2 | num_updates 15862 | best_loss 4.387
2021-11-24 01:22:03 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:22:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint115.pt (epoch 115 @ 15862 updates, score 4.39) (writing took 1.255280811994453 seconds)
2021-11-24 01:22:04 | INFO | fairseq_cli.train | end of epoch 115 (average epoch stats below)
2021-11-24 01:22:04 | INFO | train | epoch 115 | loss 3.886 | nll_loss 2.374 | distil_rate 0 | ppl 5.18 | wps 106757 | ups 3.74 | wpb 28533.3 | bsz 1160.2 | num_updates 15862 | lr 0.000430521 | gnorm 0.451 | loss_scale 34 | train_wall 31 | wall 0
2021-11-24 01:22:04 | INFO | fairseq.trainer | begin training epoch 116
2021-11-24 01:22:15 | INFO | train_inner | epoch 116:     38 / 138 loss=3.879, nll_loss=2.367, distil_rate=0, ppl=5.16, wps=100748, ups=3.54, wpb=28490.1, bsz=1170.2, num_updates=15900, lr=0.000430007, gnorm=0.45, loss_scale=35, train_wall=23, wall=0
2021-11-24 01:22:38 | INFO | train_inner | epoch 116:    138 / 138 loss=3.901, nll_loss=2.391, distil_rate=0, ppl=5.25, wps=123791, ups=4.34, wpb=28497.8, bsz=1136.6, num_updates=16000, lr=0.000428661, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:22:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:22:40 | INFO | valid | epoch 116 | valid on 'valid' subset | loss 4.431 | nll_loss 2.692 | distil_rate 0 | ppl 6.46 | wps 306385 | wpb 11163.9 | bsz 455.2 | num_updates 16000 | best_loss 4.387
2021-11-24 01:22:40 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:22:41 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint116.pt (epoch 116 @ 16000 updates, score 4.431) (writing took 1.4458021459940937 seconds)
2021-11-24 01:22:42 | INFO | fairseq_cli.train | end of epoch 116 (average epoch stats below)
2021-11-24 01:22:42 | INFO | train | epoch 116 | loss 3.882 | nll_loss 2.37 | distil_rate 0 | ppl 5.17 | wps 104304 | ups 3.66 | wpb 28536.4 | bsz 1156.9 | num_updates 16000 | lr 0.000428661 | gnorm 0.44 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:22:42 | INFO | fairseq.trainer | begin training epoch 117
2021-11-24 01:23:06 | INFO | train_inner | epoch 117:    100 / 138 loss=3.88, nll_loss=2.367, distil_rate=0, ppl=5.16, wps=99186.2, ups=3.48, wpb=28527.2, bsz=1138.2, num_updates=16100, lr=0.000427327, gnorm=0.444, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:23:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:23:18 | INFO | valid | epoch 117 | valid on 'valid' subset | loss 4.413 | nll_loss 2.673 | distil_rate 0 | ppl 6.38 | wps 322184 | wpb 11163.9 | bsz 455.2 | num_updates 16138 | best_loss 4.387
2021-11-24 01:23:18 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:23:19 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint117.pt (epoch 117 @ 16138 updates, score 4.413) (writing took 1.3662354409971158 seconds)
2021-11-24 01:23:19 | INFO | fairseq_cli.train | end of epoch 117 (average epoch stats below)
2021-11-24 01:23:19 | INFO | train | epoch 117 | loss 3.879 | nll_loss 2.366 | distil_rate 0 | ppl 5.15 | wps 106470 | ups 3.73 | wpb 28534.3 | bsz 1159.1 | num_updates 16138 | lr 0.000426824 | gnorm 0.445 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:23:19 | INFO | fairseq.trainer | begin training epoch 118
2021-11-24 01:23:35 | INFO | train_inner | epoch 118:     62 / 138 loss=3.863, nll_loss=2.348, distil_rate=0, ppl=5.09, wps=101078, ups=3.53, wpb=28607.3, bsz=1183.3, num_updates=16200, lr=0.000426006, gnorm=0.441, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:23:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:23:54 | INFO | valid | epoch 118 | valid on 'valid' subset | loss 4.416 | nll_loss 2.681 | distil_rate 0 | ppl 6.41 | wps 325513 | wpb 11163.9 | bsz 455.2 | num_updates 16276 | best_loss 4.387
2021-11-24 01:23:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:23:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint118.pt (epoch 118 @ 16276 updates, score 4.416) (writing took 1.2838114830010454 seconds)
2021-11-24 01:23:55 | INFO | fairseq_cli.train | end of epoch 118 (average epoch stats below)
2021-11-24 01:23:55 | INFO | train | epoch 118 | loss 3.875 | nll_loss 2.361 | distil_rate 0 | ppl 5.14 | wps 107690 | ups 3.77 | wpb 28530.3 | bsz 1156.9 | num_updates 16276 | lr 0.000425011 | gnorm 0.443 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:23:55 | INFO | fairseq.trainer | begin training epoch 119
2021-11-24 01:24:03 | INFO | train_inner | epoch 119:     24 / 138 loss=3.872, nll_loss=2.358, distil_rate=0, ppl=5.13, wps=101734, ups=3.57, wpb=28481.4, bsz=1184.6, num_updates=16300, lr=0.000424698, gnorm=0.448, loss_scale=32, train_wall=22, wall=0
2021-11-24 01:24:25 | INFO | train_inner | epoch 119:    124 / 138 loss=3.887, nll_loss=2.375, distil_rate=0, ppl=5.19, wps=126595, ups=4.41, wpb=28686.2, bsz=1121.2, num_updates=16400, lr=0.000423401, gnorm=0.436, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:24:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:24:31 | INFO | valid | epoch 119 | valid on 'valid' subset | loss 4.382 | nll_loss 2.649 | distil_rate 0 | ppl 6.27 | wps 283067 | wpb 11163.9 | bsz 455.2 | num_updates 16414 | best_loss 4.382
2021-11-24 01:24:31 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:24:34 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint119.pt (epoch 119 @ 16414 updates, score 4.382) (writing took 3.0181186710033217 seconds)
2021-11-24 01:24:34 | INFO | fairseq_cli.train | end of epoch 119 (average epoch stats below)
2021-11-24 01:24:34 | INFO | train | epoch 119 | loss 3.87 | nll_loss 2.356 | distil_rate 0 | ppl 5.12 | wps 102318 | ups 3.59 | wpb 28538.6 | bsz 1159.5 | num_updates 16414 | lr 0.00042322 | gnorm 0.445 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:24:34 | INFO | fairseq.trainer | begin training epoch 120
2021-11-24 01:24:56 | INFO | train_inner | epoch 120:     86 / 138 loss=3.864, nll_loss=2.349, distil_rate=0, ppl=5.09, wps=94434.4, ups=3.31, wpb=28505.6, bsz=1145.6, num_updates=16500, lr=0.000422116, gnorm=0.452, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:25:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:25:10 | INFO | valid | epoch 120 | valid on 'valid' subset | loss 4.404 | nll_loss 2.671 | distil_rate 0 | ppl 6.37 | wps 277594 | wpb 11163.9 | bsz 455.2 | num_updates 16552 | best_loss 4.382
2021-11-24 01:25:10 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:25:11 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint120.pt (epoch 120 @ 16552 updates, score 4.404) (writing took 1.3598020659992471 seconds)
2021-11-24 01:25:11 | INFO | fairseq_cli.train | end of epoch 120 (average epoch stats below)
2021-11-24 01:25:11 | INFO | train | epoch 120 | loss 3.868 | nll_loss 2.354 | distil_rate 0 | ppl 5.11 | wps 106140 | ups 3.72 | wpb 28540.3 | bsz 1159.5 | num_updates 16552 | lr 0.000421452 | gnorm 0.445 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:25:11 | INFO | fairseq.trainer | begin training epoch 121
2021-11-24 01:25:23 | INFO | train_inner | epoch 121:     48 / 138 loss=3.854, nll_loss=2.338, distil_rate=0, ppl=5.06, wps=101858, ups=3.57, wpb=28493.3, bsz=1191.3, num_updates=16600, lr=0.000420843, gnorm=0.445, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:25:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:25:47 | INFO | valid | epoch 121 | valid on 'valid' subset | loss 4.414 | nll_loss 2.677 | distil_rate 0 | ppl 6.39 | wps 295950 | wpb 11163.9 | bsz 455.2 | num_updates 16690 | best_loss 4.382
2021-11-24 01:25:47 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:25:48 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint121.pt (epoch 121 @ 16690 updates, score 4.414) (writing took 1.2482400119988597 seconds)
2021-11-24 01:25:48 | INFO | fairseq_cli.train | end of epoch 121 (average epoch stats below)
2021-11-24 01:25:48 | INFO | train | epoch 121 | loss 3.866 | nll_loss 2.351 | distil_rate 0 | ppl 5.1 | wps 106958 | ups 3.75 | wpb 28540.8 | bsz 1157.2 | num_updates 16690 | lr 0.000419706 | gnorm 0.443 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:25:48 | INFO | fairseq.trainer | begin training epoch 122
2021-11-24 01:25:52 | INFO | train_inner | epoch 122:     10 / 138 loss=3.877, nll_loss=2.364, distil_rate=0, ppl=5.15, wps=100305, ups=3.52, wpb=28471.3, bsz=1147.2, num_updates=16700, lr=0.000419581, gnorm=0.445, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:26:15 | INFO | train_inner | epoch 122:    110 / 138 loss=3.858, nll_loss=2.342, distil_rate=0, ppl=5.07, wps=124001, ups=4.33, wpb=28658.5, bsz=1165.1, num_updates=16800, lr=0.00041833, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:26:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:26:24 | INFO | valid | epoch 122 | valid on 'valid' subset | loss 4.43 | nll_loss 2.691 | distil_rate 0 | ppl 6.46 | wps 266381 | wpb 11163.9 | bsz 455.2 | num_updates 16828 | best_loss 4.382
2021-11-24 01:26:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:26:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint122.pt (epoch 122 @ 16828 updates, score 4.43) (writing took 1.229537548002554 seconds)
2021-11-24 01:26:25 | INFO | fairseq_cli.train | end of epoch 122 (average epoch stats below)
2021-11-24 01:26:25 | INFO | train | epoch 122 | loss 3.863 | nll_loss 2.348 | distil_rate 0 | ppl 5.09 | wps 106010 | ups 3.71 | wpb 28537.8 | bsz 1156.8 | num_updates 16828 | lr 0.000417982 | gnorm 0.446 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:26:25 | INFO | fairseq.trainer | begin training epoch 123
2021-11-24 01:26:43 | INFO | train_inner | epoch 123:     72 / 138 loss=3.866, nll_loss=2.351, distil_rate=0, ppl=5.1, wps=100466, ups=3.53, wpb=28498.7, bsz=1145.2, num_updates=16900, lr=0.000417091, gnorm=0.441, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:26:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:27:01 | INFO | valid | epoch 123 | valid on 'valid' subset | loss 4.461 | nll_loss 2.722 | distil_rate 0 | ppl 6.6 | wps 319628 | wpb 11163.9 | bsz 455.2 | num_updates 16966 | best_loss 4.382
2021-11-24 01:27:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:27:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint123.pt (epoch 123 @ 16966 updates, score 4.461) (writing took 1.292046537004353 seconds)
2021-11-24 01:27:02 | INFO | fairseq_cli.train | end of epoch 123 (average epoch stats below)
2021-11-24 01:27:02 | INFO | train | epoch 123 | loss 3.858 | nll_loss 2.342 | distil_rate 0 | ppl 5.07 | wps 105676 | ups 3.7 | wpb 28538.6 | bsz 1157.6 | num_updates 16966 | lr 0.000416278 | gnorm 0.442 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:27:02 | INFO | fairseq.trainer | begin training epoch 124
2021-11-24 01:27:12 | INFO | train_inner | epoch 124:     34 / 138 loss=3.846, nll_loss=2.329, distil_rate=0, ppl=5.02, wps=99991.5, ups=3.51, wpb=28509.3, bsz=1163.9, num_updates=17000, lr=0.000415862, gnorm=0.445, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:27:35 | INFO | train_inner | epoch 124:    134 / 138 loss=3.866, nll_loss=2.352, distil_rate=0, ppl=5.1, wps=125667, ups=4.38, wpb=28662, bsz=1163.8, num_updates=17100, lr=0.000414644, gnorm=0.433, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:27:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:27:38 | INFO | valid | epoch 124 | valid on 'valid' subset | loss 4.419 | nll_loss 2.679 | distil_rate 0 | ppl 6.4 | wps 250236 | wpb 11163.9 | bsz 455.2 | num_updates 17104 | best_loss 4.382
2021-11-24 01:27:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:27:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint124.pt (epoch 124 @ 17104 updates, score 4.419) (writing took 1.3353337860025931 seconds)
2021-11-24 01:27:39 | INFO | fairseq_cli.train | end of epoch 124 (average epoch stats below)
2021-11-24 01:27:39 | INFO | train | epoch 124 | loss 3.855 | nll_loss 2.339 | distil_rate 0 | ppl 5.06 | wps 106432 | ups 3.73 | wpb 28536.3 | bsz 1158.7 | num_updates 17104 | lr 0.000414596 | gnorm 0.44 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:27:39 | INFO | fairseq.trainer | begin training epoch 125
2021-11-24 01:28:03 | INFO | train_inner | epoch 125:     96 / 138 loss=3.848, nll_loss=2.33, distil_rate=0, ppl=5.03, wps=99581.1, ups=3.51, wpb=28347.5, bsz=1149.5, num_updates=17200, lr=0.000413437, gnorm=0.451, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:28:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:28:15 | INFO | valid | epoch 125 | valid on 'valid' subset | loss 4.414 | nll_loss 2.675 | distil_rate 0 | ppl 6.39 | wps 294996 | wpb 11163.9 | bsz 455.2 | num_updates 17242 | best_loss 4.382
2021-11-24 01:28:15 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:28:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint125.pt (epoch 125 @ 17242 updates, score 4.414) (writing took 1.3952302079997025 seconds)
2021-11-24 01:28:17 | INFO | fairseq_cli.train | end of epoch 125 (average epoch stats below)
2021-11-24 01:28:17 | INFO | train | epoch 125 | loss 3.854 | nll_loss 2.338 | distil_rate 0 | ppl 5.05 | wps 105136 | ups 3.68 | wpb 28536.8 | bsz 1158.5 | num_updates 17242 | lr 0.000412933 | gnorm 0.449 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:28:17 | INFO | fairseq.trainer | begin training epoch 126
2021-11-24 01:28:32 | INFO | train_inner | epoch 126:     58 / 138 loss=3.84, nll_loss=2.321, distil_rate=0, ppl=5, wps=99964.4, ups=3.49, wpb=28644.3, bsz=1180.8, num_updates=17300, lr=0.00041224, gnorm=0.454, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:28:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:28:53 | INFO | valid | epoch 126 | valid on 'valid' subset | loss 4.418 | nll_loss 2.676 | distil_rate 0 | ppl 6.39 | wps 325492 | wpb 11163.9 | bsz 455.2 | num_updates 17380 | best_loss 4.382
2021-11-24 01:28:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:28:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint126.pt (epoch 126 @ 17380 updates, score 4.418) (writing took 1.2882283799990546 seconds)
2021-11-24 01:28:54 | INFO | fairseq_cli.train | end of epoch 126 (average epoch stats below)
2021-11-24 01:28:54 | INFO | train | epoch 126 | loss 3.85 | nll_loss 2.333 | distil_rate 0 | ppl 5.04 | wps 105944 | ups 3.71 | wpb 28538.7 | bsz 1156.5 | num_updates 17380 | lr 0.000411291 | gnorm 0.445 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:28:54 | INFO | fairseq.trainer | begin training epoch 127
2021-11-24 01:29:00 | INFO | train_inner | epoch 127:     20 / 138 loss=3.857, nll_loss=2.341, distil_rate=0, ppl=5.07, wps=100747, ups=3.54, wpb=28471.6, bsz=1140.6, num_updates=17400, lr=0.000411054, gnorm=0.441, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:29:23 | INFO | train_inner | epoch 127:    120 / 138 loss=3.857, nll_loss=2.34, distil_rate=0, ppl=5.06, wps=124422, ups=4.35, wpb=28603.6, bsz=1138.4, num_updates=17500, lr=0.000409878, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:29:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:29:30 | INFO | valid | epoch 127 | valid on 'valid' subset | loss 4.401 | nll_loss 2.667 | distil_rate 0 | ppl 6.35 | wps 205945 | wpb 11163.9 | bsz 455.2 | num_updates 17518 | best_loss 4.382
2021-11-24 01:29:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:29:31 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint127.pt (epoch 127 @ 17518 updates, score 4.401) (writing took 1.3737050049967365 seconds)
2021-11-24 01:29:31 | INFO | fairseq_cli.train | end of epoch 127 (average epoch stats below)
2021-11-24 01:29:31 | INFO | train | epoch 127 | loss 3.848 | nll_loss 2.331 | distil_rate 0 | ppl 5.03 | wps 106343 | ups 3.73 | wpb 28543 | bsz 1159.2 | num_updates 17518 | lr 0.000409667 | gnorm 0.446 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:29:31 | INFO | fairseq.trainer | begin training epoch 128
2021-11-24 01:29:52 | INFO | train_inner | epoch 128:     82 / 138 loss=3.851, nll_loss=2.334, distil_rate=0, ppl=5.04, wps=98087.6, ups=3.44, wpb=28500.3, bsz=1156.2, num_updates=17600, lr=0.000408712, gnorm=0.451, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:30:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:30:08 | INFO | valid | epoch 128 | valid on 'valid' subset | loss 4.407 | nll_loss 2.667 | distil_rate 0 | ppl 6.35 | wps 311216 | wpb 11163.9 | bsz 455.2 | num_updates 17656 | best_loss 4.382
2021-11-24 01:30:08 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:30:09 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint128.pt (epoch 128 @ 17656 updates, score 4.407) (writing took 1.2601191810026648 seconds)
2021-11-24 01:30:09 | INFO | fairseq_cli.train | end of epoch 128 (average epoch stats below)
2021-11-24 01:30:09 | INFO | train | epoch 128 | loss 3.846 | nll_loss 2.329 | distil_rate 0 | ppl 5.02 | wps 103301 | ups 3.62 | wpb 28530 | bsz 1156.3 | num_updates 17656 | lr 0.000408063 | gnorm 0.452 | loss_scale 32 | train_wall 33 | wall 0
2021-11-24 01:30:09 | INFO | fairseq.trainer | begin training epoch 129
2021-11-24 01:30:21 | INFO | train_inner | epoch 129:     44 / 138 loss=3.837, nll_loss=2.318, distil_rate=0, ppl=4.99, wps=97971.1, ups=3.44, wpb=28476, bsz=1174.3, num_updates=17700, lr=0.000407556, gnorm=0.456, loss_scale=32, train_wall=24, wall=0
2021-11-24 01:30:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:30:46 | INFO | valid | epoch 129 | valid on 'valid' subset | loss 4.416 | nll_loss 2.675 | distil_rate 0 | ppl 6.39 | wps 281857 | wpb 11163.9 | bsz 455.2 | num_updates 17794 | best_loss 4.382
2021-11-24 01:30:46 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:30:47 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint129.pt (epoch 129 @ 17794 updates, score 4.416) (writing took 1.1263846439978806 seconds)
2021-11-24 01:30:47 | INFO | fairseq_cli.train | end of epoch 129 (average epoch stats below)
2021-11-24 01:30:47 | INFO | train | epoch 129 | loss 3.842 | nll_loss 2.324 | distil_rate 0 | ppl 5.01 | wps 103947 | ups 3.64 | wpb 28541.2 | bsz 1159.2 | num_updates 17794 | lr 0.000406478 | gnorm 0.45 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:30:47 | INFO | fairseq.trainer | begin training epoch 130
2021-11-24 01:30:50 | INFO | train_inner | epoch 130:      6 / 138 loss=3.845, nll_loss=2.327, distil_rate=0, ppl=5.02, wps=98792, ups=3.46, wpb=28569.3, bsz=1156.2, num_updates=17800, lr=0.000406409, gnorm=0.452, loss_scale=32, train_wall=24, wall=0
2021-11-24 01:31:14 | INFO | train_inner | epoch 130:    106 / 138 loss=3.835, nll_loss=2.316, distil_rate=0, ppl=4.98, wps=120499, ups=4.19, wpb=28733.2, bsz=1175.4, num_updates=17900, lr=0.000405273, gnorm=0.446, loss_scale=33, train_wall=24, wall=0
2021-11-24 01:31:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-11-24 01:31:21 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:31:24 | INFO | valid | epoch 130 | valid on 'valid' subset | loss 4.438 | nll_loss 2.697 | distil_rate 0 | ppl 6.49 | wps 305417 | wpb 11163.9 | bsz 455.2 | num_updates 17931 | best_loss 4.382
2021-11-24 01:31:24 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:31:25 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint130.pt (epoch 130 @ 17931 updates, score 4.438) (writing took 1.2656777299998794 seconds)
2021-11-24 01:31:25 | INFO | fairseq_cli.train | end of epoch 130 (average epoch stats below)
2021-11-24 01:31:25 | INFO | train | epoch 130 | loss 3.84 | nll_loss 2.322 | distil_rate 0 | ppl 5 | wps 102729 | ups 3.6 | wpb 28535.6 | bsz 1158.5 | num_updates 17931 | lr 0.000404922 | gnorm 0.454 | loss_scale 35 | train_wall 33 | wall 0
2021-11-24 01:31:25 | INFO | fairseq.trainer | begin training epoch 131
2021-11-24 01:31:42 | INFO | train_inner | epoch 131:     69 / 138 loss=3.835, nll_loss=2.316, distil_rate=0, ppl=4.98, wps=99648.6, ups=3.51, wpb=28398.8, bsz=1133, num_updates=18000, lr=0.000404145, gnorm=0.446, loss_scale=35, train_wall=23, wall=0
2021-11-24 01:31:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:32:01 | INFO | valid | epoch 131 | valid on 'valid' subset | loss 4.435 | nll_loss 2.689 | distil_rate 0 | ppl 6.45 | wps 291506 | wpb 11163.9 | bsz 455.2 | num_updates 18069 | best_loss 4.382
2021-11-24 01:32:01 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:32:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint131.pt (epoch 131 @ 18069 updates, score 4.435) (writing took 1.266523366997717 seconds)
2021-11-24 01:32:02 | INFO | fairseq_cli.train | end of epoch 131 (average epoch stats below)
2021-11-24 01:32:02 | INFO | train | epoch 131 | loss 3.834 | nll_loss 2.315 | distil_rate 0 | ppl 4.98 | wps 106974 | ups 3.75 | wpb 28547.1 | bsz 1160.2 | num_updates 18069 | lr 0.000403373 | gnorm 0.45 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:32:02 | INFO | fairseq.trainer | begin training epoch 132
2021-11-24 01:32:11 | INFO | train_inner | epoch 132:     31 / 138 loss=3.836, nll_loss=2.317, distil_rate=0, ppl=4.98, wps=100542, ups=3.53, wpb=28481.5, bsz=1166.9, num_updates=18100, lr=0.000403027, gnorm=0.465, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:32:34 | INFO | train_inner | epoch 132:    131 / 138 loss=3.841, nll_loss=2.323, distil_rate=0, ppl=5, wps=124725, ups=4.34, wpb=28727.8, bsz=1168.1, num_updates=18200, lr=0.000401918, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:32:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:32:38 | INFO | valid | epoch 132 | valid on 'valid' subset | loss 4.425 | nll_loss 2.682 | distil_rate 0 | ppl 6.42 | wps 240798 | wpb 11163.9 | bsz 455.2 | num_updates 18207 | best_loss 4.382
2021-11-24 01:32:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:32:39 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint132.pt (epoch 132 @ 18207 updates, score 4.425) (writing took 1.5784831639975891 seconds)
2021-11-24 01:32:39 | INFO | fairseq_cli.train | end of epoch 132 (average epoch stats below)
2021-11-24 01:32:39 | INFO | train | epoch 132 | loss 3.833 | nll_loss 2.314 | distil_rate 0 | ppl 4.97 | wps 104785 | ups 3.67 | wpb 28540.1 | bsz 1159.4 | num_updates 18207 | lr 0.000401841 | gnorm 0.452 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:32:39 | INFO | fairseq.trainer | begin training epoch 133
2021-11-24 01:33:03 | INFO | train_inner | epoch 133:     93 / 138 loss=3.82, nll_loss=2.299, distil_rate=0, ppl=4.92, wps=98786.9, ups=3.47, wpb=28476, bsz=1172.4, num_updates=18300, lr=0.000400819, gnorm=0.455, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:33:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:33:16 | INFO | valid | epoch 133 | valid on 'valid' subset | loss 4.419 | nll_loss 2.674 | distil_rate 0 | ppl 6.38 | wps 264256 | wpb 11163.9 | bsz 455.2 | num_updates 18345 | best_loss 4.382
2021-11-24 01:33:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:33:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint133.pt (epoch 133 @ 18345 updates, score 4.419) (writing took 1.2356431980006164 seconds)
2021-11-24 01:33:17 | INFO | fairseq_cli.train | end of epoch 133 (average epoch stats below)
2021-11-24 01:33:17 | INFO | train | epoch 133 | loss 3.831 | nll_loss 2.312 | distil_rate 0 | ppl 4.96 | wps 105264 | ups 3.69 | wpb 28541.4 | bsz 1158.9 | num_updates 18345 | lr 0.000400327 | gnorm 0.453 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:33:17 | INFO | fairseq.trainer | begin training epoch 134
2021-11-24 01:33:31 | INFO | train_inner | epoch 134:     55 / 138 loss=3.825, nll_loss=2.305, distil_rate=0, ppl=4.94, wps=98842.8, ups=3.46, wpb=28529, bsz=1157.4, num_updates=18400, lr=0.000399728, gnorm=0.45, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:33:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:33:53 | INFO | valid | epoch 134 | valid on 'valid' subset | loss 4.425 | nll_loss 2.683 | distil_rate 0 | ppl 6.42 | wps 286758 | wpb 11163.9 | bsz 455.2 | num_updates 18483 | best_loss 4.382
2021-11-24 01:33:53 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:33:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint134.pt (epoch 134 @ 18483 updates, score 4.425) (writing took 1.2710534729994833 seconds)
2021-11-24 01:33:54 | INFO | fairseq_cli.train | end of epoch 134 (average epoch stats below)
2021-11-24 01:33:54 | INFO | train | epoch 134 | loss 3.829 | nll_loss 2.309 | distil_rate 0 | ppl 4.95 | wps 104944 | ups 3.68 | wpb 28540.3 | bsz 1158.1 | num_updates 18483 | lr 0.00039883 | gnorm 0.454 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:33:54 | INFO | fairseq.trainer | begin training epoch 135
2021-11-24 01:34:00 | INFO | train_inner | epoch 135:     17 / 138 loss=3.839, nll_loss=2.32, distil_rate=0, ppl=4.99, wps=99232.3, ups=3.49, wpb=28397.9, bsz=1136.9, num_updates=18500, lr=0.000398646, gnorm=0.465, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:34:23 | INFO | train_inner | epoch 135:    117 / 138 loss=3.821, nll_loss=2.3, distil_rate=0, ppl=4.92, wps=126042, ups=4.38, wpb=28805.6, bsz=1180.9, num_updates=18600, lr=0.000397573, gnorm=0.435, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:34:28 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:34:30 | INFO | valid | epoch 135 | valid on 'valid' subset | loss 4.407 | nll_loss 2.668 | distil_rate 0 | ppl 6.36 | wps 323274 | wpb 11163.9 | bsz 455.2 | num_updates 18621 | best_loss 4.382
2021-11-24 01:34:30 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:34:32 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint135.pt (epoch 135 @ 18621 updates, score 4.407) (writing took 1.425665789996856 seconds)
2021-11-24 01:34:32 | INFO | fairseq_cli.train | end of epoch 135 (average epoch stats below)
2021-11-24 01:34:32 | INFO | train | epoch 135 | loss 3.826 | nll_loss 2.306 | distil_rate 0 | ppl 4.94 | wps 105942 | ups 3.71 | wpb 28536.2 | bsz 1158 | num_updates 18621 | lr 0.000397349 | gnorm 0.45 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:34:32 | INFO | fairseq.trainer | begin training epoch 136
2021-11-24 01:34:51 | INFO | train_inner | epoch 136:     79 / 138 loss=3.814, nll_loss=2.291, distil_rate=0, ppl=4.89, wps=100287, ups=3.52, wpb=28473, bsz=1153, num_updates=18700, lr=0.000396509, gnorm=0.454, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:35:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:35:07 | INFO | valid | epoch 136 | valid on 'valid' subset | loss 4.428 | nll_loss 2.684 | distil_rate 0 | ppl 6.42 | wps 265974 | wpb 11163.9 | bsz 455.2 | num_updates 18759 | best_loss 4.382
2021-11-24 01:35:07 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:35:08 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint136.pt (epoch 136 @ 18759 updates, score 4.428) (writing took 1.1222755950002465 seconds)
2021-11-24 01:35:08 | INFO | fairseq_cli.train | end of epoch 136 (average epoch stats below)
2021-11-24 01:35:08 | INFO | train | epoch 136 | loss 3.824 | nll_loss 2.304 | distil_rate 0 | ppl 4.94 | wps 106760 | ups 3.74 | wpb 28546.2 | bsz 1157.7 | num_updates 18759 | lr 0.000395885 | gnorm 0.449 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:35:08 | INFO | fairseq.trainer | begin training epoch 137
2021-11-24 01:35:19 | INFO | train_inner | epoch 137:     41 / 138 loss=3.839, nll_loss=2.32, distil_rate=0, ppl=4.99, wps=101060, ups=3.56, wpb=28409.4, bsz=1134.2, num_updates=18800, lr=0.000395453, gnorm=0.456, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:35:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:35:44 | INFO | valid | epoch 137 | valid on 'valid' subset | loss 4.427 | nll_loss 2.684 | distil_rate 0 | ppl 6.43 | wps 279591 | wpb 11163.9 | bsz 455.2 | num_updates 18897 | best_loss 4.382
2021-11-24 01:35:44 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:35:46 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint137.pt (epoch 137 @ 18897 updates, score 4.427) (writing took 1.4742655110021587 seconds)
2021-11-24 01:35:46 | INFO | fairseq_cli.train | end of epoch 137 (average epoch stats below)
2021-11-24 01:35:46 | INFO | train | epoch 137 | loss 3.821 | nll_loss 2.3 | distil_rate 0 | ppl 4.92 | wps 106157 | ups 3.72 | wpb 28534.5 | bsz 1157.8 | num_updates 18897 | lr 0.000394437 | gnorm 0.455 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:35:46 | INFO | fairseq.trainer | begin training epoch 138
2021-11-24 01:35:48 | INFO | train_inner | epoch 138:      3 / 138 loss=3.819, nll_loss=2.298, distil_rate=0, ppl=4.92, wps=99559.2, ups=3.5, wpb=28486.1, bsz=1172.6, num_updates=18900, lr=0.000394405, gnorm=0.458, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:36:11 | INFO | train_inner | epoch 138:    103 / 138 loss=3.814, nll_loss=2.292, distil_rate=0, ppl=4.9, wps=126020, ups=4.38, wpb=28785.9, bsz=1162, num_updates=19000, lr=0.000393366, gnorm=0.443, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:36:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:36:21 | INFO | valid | epoch 138 | valid on 'valid' subset | loss 4.428 | nll_loss 2.681 | distil_rate 0 | ppl 6.41 | wps 238552 | wpb 11163.9 | bsz 455.2 | num_updates 19035 | best_loss 4.382
2021-11-24 01:36:21 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:36:23 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint138.pt (epoch 138 @ 19035 updates, score 4.428) (writing took 1.3035826920022373 seconds)
2021-11-24 01:36:23 | INFO | fairseq_cli.train | end of epoch 138 (average epoch stats below)
2021-11-24 01:36:23 | INFO | train | epoch 138 | loss 3.819 | nll_loss 2.297 | distil_rate 0 | ppl 4.92 | wps 106007 | ups 3.71 | wpb 28535.3 | bsz 1157.7 | num_updates 19035 | lr 0.000393004 | gnorm 0.45 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:36:23 | INFO | fairseq.trainer | begin training epoch 139
2021-11-24 01:36:39 | INFO | train_inner | epoch 139:     65 / 138 loss=3.798, nll_loss=2.275, distil_rate=0, ppl=4.84, wps=99810.2, ups=3.52, wpb=28346.2, bsz=1185.1, num_updates=19100, lr=0.000392335, gnorm=0.447, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:36:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:36:59 | INFO | valid | epoch 139 | valid on 'valid' subset | loss 4.421 | nll_loss 2.677 | distil_rate 0 | ppl 6.4 | wps 323835 | wpb 11163.9 | bsz 455.2 | num_updates 19173 | best_loss 4.382
2021-11-24 01:36:59 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:37:00 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint139.pt (epoch 139 @ 19173 updates, score 4.421) (writing took 1.647506680994411 seconds)
2021-11-24 01:37:00 | INFO | fairseq_cli.train | end of epoch 139 (average epoch stats below)
2021-11-24 01:37:00 | INFO | train | epoch 139 | loss 3.814 | nll_loss 2.292 | distil_rate 0 | ppl 4.9 | wps 104824 | ups 3.67 | wpb 28533.9 | bsz 1158.7 | num_updates 19173 | lr 0.000391587 | gnorm 0.448 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:37:00 | INFO | fairseq.trainer | begin training epoch 140
2021-11-24 01:37:08 | INFO | train_inner | epoch 140:     27 / 138 loss=3.834, nll_loss=2.315, distil_rate=0, ppl=4.98, wps=98755.5, ups=3.46, wpb=28579.3, bsz=1127.4, num_updates=19200, lr=0.000391312, gnorm=0.457, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:37:31 | INFO | train_inner | epoch 140:    127 / 138 loss=3.815, nll_loss=2.294, distil_rate=0, ppl=4.9, wps=123963, ups=4.34, wpb=28583.1, bsz=1161.8, num_updates=19300, lr=0.000390297, gnorm=0.445, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:37:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:37:36 | INFO | valid | epoch 140 | valid on 'valid' subset | loss 4.401 | nll_loss 2.658 | distil_rate 0 | ppl 6.31 | wps 322948 | wpb 11163.9 | bsz 455.2 | num_updates 19311 | best_loss 4.382
2021-11-24 01:37:36 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:37:38 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint140.pt (epoch 140 @ 19311 updates, score 4.401) (writing took 1.5049208579948754 seconds)
2021-11-24 01:37:38 | INFO | fairseq_cli.train | end of epoch 140 (average epoch stats below)
2021-11-24 01:37:38 | INFO | train | epoch 140 | loss 3.813 | nll_loss 2.292 | distil_rate 0 | ppl 4.9 | wps 104908 | ups 3.68 | wpb 28534.2 | bsz 1155.7 | num_updates 19311 | lr 0.000390186 | gnorm 0.453 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:37:38 | INFO | fairseq.trainer | begin training epoch 141
2021-11-24 01:38:00 | INFO | train_inner | epoch 141:     89 / 138 loss=3.809, nll_loss=2.287, distil_rate=0, ppl=4.88, wps=101111, ups=3.55, wpb=28491.7, bsz=1150.2, num_updates=19400, lr=0.00038929, gnorm=0.461, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:38:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:38:13 | INFO | valid | epoch 141 | valid on 'valid' subset | loss 4.391 | nll_loss 2.657 | distil_rate 0 | ppl 6.31 | wps 268267 | wpb 11163.9 | bsz 455.2 | num_updates 19449 | best_loss 4.382
2021-11-24 01:38:13 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:38:14 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint141.pt (epoch 141 @ 19449 updates, score 4.391) (writing took 1.17360429999826 seconds)
2021-11-24 01:38:14 | INFO | fairseq_cli.train | end of epoch 141 (average epoch stats below)
2021-11-24 01:38:14 | INFO | train | epoch 141 | loss 3.811 | nll_loss 2.289 | distil_rate 0 | ppl 4.89 | wps 107819 | ups 3.78 | wpb 28538.4 | bsz 1158.6 | num_updates 19449 | lr 0.000388799 | gnorm 0.458 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:38:14 | INFO | fairseq.trainer | begin training epoch 142
2021-11-24 01:38:28 | INFO | train_inner | epoch 142:     51 / 138 loss=3.806, nll_loss=2.282, distil_rate=0, ppl=4.86, wps=101249, ups=3.55, wpb=28540.8, bsz=1163.9, num_updates=19500, lr=0.00038829, gnorm=0.457, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:38:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:38:50 | INFO | valid | epoch 142 | valid on 'valid' subset | loss 4.382 | nll_loss 2.647 | distil_rate 0 | ppl 6.26 | wps 313003 | wpb 11163.9 | bsz 455.2 | num_updates 19587 | best_loss 4.382
2021-11-24 01:38:50 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:38:53 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint142.pt (epoch 142 @ 19587 updates, score 4.382) (writing took 2.9066004720007186 seconds)
2021-11-24 01:38:53 | INFO | fairseq_cli.train | end of epoch 142 (average epoch stats below)
2021-11-24 01:38:53 | INFO | train | epoch 142 | loss 3.806 | nll_loss 2.283 | distil_rate 0 | ppl 4.87 | wps 102098 | ups 3.58 | wpb 28537.9 | bsz 1158.8 | num_updates 19587 | lr 0.000387427 | gnorm 0.448 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:38:53 | INFO | fairseq.trainer | begin training epoch 143
2021-11-24 01:38:58 | INFO | train_inner | epoch 143:     13 / 138 loss=3.813, nll_loss=2.291, distil_rate=0, ppl=4.89, wps=95143.2, ups=3.34, wpb=28449.8, bsz=1154.5, num_updates=19600, lr=0.000387298, gnorm=0.452, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:39:20 | INFO | train_inner | epoch 143:    113 / 138 loss=3.806, nll_loss=2.282, distil_rate=0, ppl=4.86, wps=124968, ups=4.37, wpb=28592.1, bsz=1147, num_updates=19700, lr=0.000386314, gnorm=0.437, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:39:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:39:29 | INFO | valid | epoch 143 | valid on 'valid' subset | loss 4.404 | nll_loss 2.662 | distil_rate 0 | ppl 6.33 | wps 238264 | wpb 11163.9 | bsz 455.2 | num_updates 19725 | best_loss 4.382
2021-11-24 01:39:29 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:39:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint143.pt (epoch 143 @ 19725 updates, score 4.404) (writing took 1.389955660000851 seconds)
2021-11-24 01:39:30 | INFO | fairseq_cli.train | end of epoch 143 (average epoch stats below)
2021-11-24 01:39:30 | INFO | train | epoch 143 | loss 3.803 | nll_loss 2.279 | distil_rate 0 | ppl 4.85 | wps 105995 | ups 3.71 | wpb 28542.6 | bsz 1159.1 | num_updates 19725 | lr 0.000386069 | gnorm 0.445 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:39:30 | INFO | fairseq.trainer | begin training epoch 144
2021-11-24 01:39:49 | INFO | train_inner | epoch 144:     75 / 138 loss=3.795, nll_loss=2.27, distil_rate=0, ppl=4.82, wps=99767.7, ups=3.5, wpb=28534.9, bsz=1162.7, num_updates=19800, lr=0.000385337, gnorm=0.453, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:40:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:40:06 | INFO | valid | epoch 144 | valid on 'valid' subset | loss 4.41 | nll_loss 2.665 | distil_rate 0 | ppl 6.34 | wps 320741 | wpb 11163.9 | bsz 455.2 | num_updates 19863 | best_loss 4.382
2021-11-24 01:40:06 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:40:07 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint144.pt (epoch 144 @ 19863 updates, score 4.41) (writing took 1.7837009040013072 seconds)
2021-11-24 01:40:07 | INFO | fairseq_cli.train | end of epoch 144 (average epoch stats below)
2021-11-24 01:40:07 | INFO | train | epoch 144 | loss 3.803 | nll_loss 2.279 | distil_rate 0 | ppl 4.85 | wps 105427 | ups 3.69 | wpb 28537.4 | bsz 1157.6 | num_updates 19863 | lr 0.000384726 | gnorm 0.451 | loss_scale 32 | train_wall 31 | wall 0
2021-11-24 01:40:07 | INFO | fairseq.trainer | begin training epoch 145
2021-11-24 01:40:18 | INFO | train_inner | epoch 145:     37 / 138 loss=3.805, nll_loss=2.282, distil_rate=0, ppl=4.86, wps=99883.6, ups=3.51, wpb=28453.9, bsz=1165, num_updates=19900, lr=0.000384368, gnorm=0.456, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:40:40 | INFO | train_inner | epoch 145:    137 / 138 loss=3.807, nll_loss=2.284, distil_rate=0, ppl=4.87, wps=125813, ups=4.38, wpb=28741.1, bsz=1160.8, num_updates=20000, lr=0.000383406, gnorm=0.455, loss_scale=46, train_wall=23, wall=0
2021-11-24 01:40:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:40:43 | INFO | valid | epoch 145 | valid on 'valid' subset | loss 4.407 | nll_loss 2.662 | distil_rate 0 | ppl 6.33 | wps 285827 | wpb 11163.9 | bsz 455.2 | num_updates 20001 | best_loss 4.382
2021-11-24 01:40:43 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:40:45 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint145.pt (epoch 145 @ 20001 updates, score 4.407) (writing took 1.4631448139989516 seconds)
2021-11-24 01:40:46 | INFO | fairseq_cli.train | end of epoch 145 (average epoch stats below)
2021-11-24 01:40:46 | INFO | train | epoch 145 | loss 3.802 | nll_loss 2.279 | distil_rate 0 | ppl 4.85 | wps 103285 | ups 3.62 | wpb 28535.9 | bsz 1157.5 | num_updates 20001 | lr 0.000383396 | gnorm 0.46 | loss_scale 42 | train_wall 31 | wall 0
2021-11-24 01:40:46 | INFO | fairseq.trainer | begin training epoch 146
2021-11-24 01:41:11 | INFO | train_inner | epoch 146:     99 / 138 loss=3.789, nll_loss=2.263, distil_rate=0, ppl=4.8, wps=94472.7, ups=3.31, wpb=28521.5, bsz=1160.1, num_updates=20100, lr=0.000382451, gnorm=0.448, loss_scale=64, train_wall=24, wall=0
2021-11-24 01:41:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:41:22 | INFO | valid | epoch 146 | valid on 'valid' subset | loss 4.421 | nll_loss 2.676 | distil_rate 0 | ppl 6.39 | wps 244563 | wpb 11163.9 | bsz 455.2 | num_updates 20139 | best_loss 4.382
2021-11-24 01:41:22 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:41:24 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint146.pt (epoch 146 @ 20139 updates, score 4.421) (writing took 1.316020997997839 seconds)
2021-11-24 01:41:24 | INFO | fairseq_cli.train | end of epoch 146 (average epoch stats below)
2021-11-24 01:41:24 | INFO | train | epoch 146 | loss 3.796 | nll_loss 2.272 | distil_rate 0 | ppl 4.83 | wps 103372 | ups 3.62 | wpb 28533.6 | bsz 1158.7 | num_updates 20139 | lr 0.00038208 | gnorm 0.447 | loss_scale 64 | train_wall 33 | wall 0
2021-11-24 01:41:24 | INFO | fairseq.trainer | begin training epoch 147
2021-11-24 01:41:40 | INFO | train_inner | epoch 147:     61 / 138 loss=3.791, nll_loss=2.266, distil_rate=0, ppl=4.81, wps=97679.4, ups=3.43, wpb=28483.4, bsz=1153.4, num_updates=20200, lr=0.000381503, gnorm=0.453, loss_scale=64, train_wall=23, wall=0
2021-11-24 01:41:54 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2021-11-24 01:41:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:42:00 | INFO | valid | epoch 147 | valid on 'valid' subset | loss 4.436 | nll_loss 2.687 | distil_rate 0 | ppl 6.44 | wps 246383 | wpb 11163.9 | bsz 455.2 | num_updates 20276 | best_loss 4.382
2021-11-24 01:42:00 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:42:02 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint147.pt (epoch 147 @ 20276 updates, score 4.436) (writing took 1.3976663929934148 seconds)
2021-11-24 01:42:02 | INFO | fairseq_cli.train | end of epoch 147 (average epoch stats below)
2021-11-24 01:42:02 | INFO | train | epoch 147 | loss 3.797 | nll_loss 2.273 | distil_rate 0 | ppl 4.83 | wps 102524 | ups 3.59 | wpb 28540.7 | bsz 1151.6 | num_updates 20276 | lr 0.000380787 | gnorm 0.448 | loss_scale 60 | train_wall 32 | wall 0
2021-11-24 01:42:02 | INFO | fairseq.trainer | begin training epoch 148
2021-11-24 01:42:09 | INFO | train_inner | epoch 148:     24 / 138 loss=3.804, nll_loss=2.28, distil_rate=0, ppl=4.86, wps=97453, ups=3.42, wpb=28535.5, bsz=1136.5, num_updates=20300, lr=0.000380562, gnorm=0.447, loss_scale=50, train_wall=23, wall=0
2021-11-24 01:42:32 | INFO | train_inner | epoch 148:    124 / 138 loss=3.804, nll_loss=2.28, distil_rate=0, ppl=4.86, wps=123486, ups=4.32, wpb=28610.8, bsz=1145.6, num_updates=20400, lr=0.000379628, gnorm=0.448, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:42:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:42:38 | INFO | valid | epoch 148 | valid on 'valid' subset | loss 4.442 | nll_loss 2.702 | distil_rate 0 | ppl 6.51 | wps 321042 | wpb 11163.9 | bsz 455.2 | num_updates 20414 | best_loss 4.382
2021-11-24 01:42:38 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:42:40 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint148.pt (epoch 148 @ 20414 updates, score 4.442) (writing took 1.5485180899995612 seconds)
2021-11-24 01:42:40 | INFO | fairseq_cli.train | end of epoch 148 (average epoch stats below)
2021-11-24 01:42:40 | INFO | train | epoch 148 | loss 3.793 | nll_loss 2.268 | distil_rate 0 | ppl 4.82 | wps 104164 | ups 3.65 | wpb 28547.1 | bsz 1157.8 | num_updates 20414 | lr 0.000379498 | gnorm 0.454 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:42:40 | INFO | fairseq.trainer | begin training epoch 149
2021-11-24 01:43:01 | INFO | train_inner | epoch 149:     86 / 138 loss=3.774, nll_loss=2.246, distil_rate=0, ppl=4.75, wps=97804.3, ups=3.43, wpb=28500.3, bsz=1206.5, num_updates=20500, lr=0.000378701, gnorm=0.461, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:43:13 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:43:16 | INFO | valid | epoch 149 | valid on 'valid' subset | loss 4.445 | nll_loss 2.704 | distil_rate 0 | ppl 6.51 | wps 252348 | wpb 11163.9 | bsz 455.2 | num_updates 20552 | best_loss 4.382
2021-11-24 01:43:16 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:43:17 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint149.pt (epoch 149 @ 20552 updates, score 4.445) (writing took 1.3799177410037373 seconds)
2021-11-24 01:43:17 | INFO | fairseq_cli.train | end of epoch 149 (average epoch stats below)
2021-11-24 01:43:17 | INFO | train | epoch 149 | loss 3.791 | nll_loss 2.266 | distil_rate 0 | ppl 4.81 | wps 104926 | ups 3.67 | wpb 28562.6 | bsz 1159.5 | num_updates 20552 | lr 0.000378222 | gnorm 0.457 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:43:17 | INFO | fairseq.trainer | begin training epoch 150
2021-11-24 01:43:30 | INFO | train_inner | epoch 150:     48 / 138 loss=3.796, nll_loss=2.271, distil_rate=0, ppl=4.83, wps=99269.2, ups=3.47, wpb=28606.7, bsz=1129.4, num_updates=20600, lr=0.000377781, gnorm=0.459, loss_scale=32, train_wall=23, wall=0
2021-11-24 01:43:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2021-11-24 01:43:54 | INFO | valid | epoch 150 | valid on 'valid' subset | loss 4.416 | nll_loss 2.669 | distil_rate 0 | ppl 6.36 | wps 320445 | wpb 11163.9 | bsz 455.2 | num_updates 20690 | best_loss 4.382
2021-11-24 01:43:54 | INFO | fairseq_cli.train | begin save checkpoint
2021-11-24 01:43:55 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/tiny-iwlst-de-en/transformer_iwlst14de2en/checkpoint150.pt (epoch 150 @ 20690 updates, score 4.416) (writing took 1.2917620899970643 seconds)
2021-11-24 01:43:55 | INFO | fairseq_cli.train | end of epoch 150 (average epoch stats below)
2021-11-24 01:43:55 | INFO | train | epoch 150 | loss 3.789 | nll_loss 2.264 | distil_rate 0 | ppl 4.8 | wps 104193 | ups 3.65 | wpb 28535.8 | bsz 1157.6 | num_updates 20690 | lr 0.000376958 | gnorm 0.455 | loss_scale 32 | train_wall 32 | wall 0
2021-11-24 01:43:55 | INFO | fairseq_cli.train | done training in 1869.8 seconds
